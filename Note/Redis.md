[TOC]

# 数据类型及结构

## 数据类型

String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet

## 底层数据结构

* String：简单动态字符串
* List：双向链表 + 压缩列表
* Hash：哈希表 + 压缩列表
* Set：整数数组+ 哈希表
* ZSet：跳表 + 压缩列表

### 哈希表

但无论值是什么类型的，所有的键值对会保存在**全局哈希表**中，便于快速找到对应的Key，哈希桶只会保存键值对的指针。

因此，即使Redis里存在大量数据，也不影响查找的速度，毕竟都是根据Key进行hash就能找到对应的Value，真正有影响的是哈希表的在解决哈希冲突和rehash时带来的阻塞。

**Redis的哈希表使用拉链法解决哈希冲突。通过两个全局哈希表加快rehash的操作。**

处理全局哈希表有这种操作，Hash的数据结构也是这样的操作，本质是一样的。

当Redis生产RDB和AOF重写时，哈希表不会进行rehash。

#### rehash触发条件

装载因子：哈希表中所有entry的个数除以哈希表的哈希桶个数。

* 当装载因子>= 1，且哈希表被允许rehash，即此时没有进行RDB和AOF重写

* 当装载因子>= 5，因为此时数据量已远远大于哈希桶的个数了，此时会立马进行rehash

#### rehash过程

1. 默认使用哈希表1，此时哈希表2还没有被分配空间

2. 当数据增多至需要rehash时，为哈希表2分配空间，大小会比哈希表1大，比如大两倍

3. 把哈希表1中的数据重新映射并拷贝到哈希表2中

   **渐进式rehash**：解决大量数据在哈希表1和2之间拷贝，会导致Redis线程阻塞（因为单线程)。

   3.1 拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺便将该索引位置上的所有entries拷贝到哈希表2中；

   3.2 等待处理下一个请求时，再顺带拷贝哈希表1中该索引下一个索引位置的entries到哈希表2中；

   通过这两种方式，将一次性的大量拷贝分散到每次请求和等待间隙中。

   3.3 此外Redis本身也有一个**定时任务**在执行rehash，发生在空闲时间

4. 释放哈希表1的空间，此时哈希表1的空间被回收，原来的哈希表2变成哈希表1，哈希表1变成哈希表2

列表

### 压缩列表

本质上是一个数组，数组中每一个元素保存一个数据。但压缩列表在

* 表头有三个字段：zlbytes记录占用的内存字节数，可算出列表长度；zltail记录列表尾的偏移量，可算出尾节点到列表起始地址的字节数；zllen记录列表中的entry个数；
* 每个节点元素entry有三个字段：previous_entry_length记录前一个节点的长度；encoding记录content的数据类型和长度；content保存元素的值
* 表尾有一字段：zlend用于标记列表末端。

压缩列表的优势在于存储结构，普通数组要求数组的每个元素的大小相同，但是当我们需要在每个元素中存储大小不同的字符串时，就会浪费存储空间，压缩列表就是会把每个元素多余的空间进行压缩，让每个元素紧密相连，再为每个元素增加一个长度，用于计算下一个元素在内存中的位置。

另外，在内存的地址查找时，在查找第一个和最后一个的时候有优势，可以利用这三个字段查到，是O(1)，但是因为存储紧凑的缘故，查找其他元素只能遍历，是O(n)。

压缩列表或者数组主要因为其数据结构紧凑，节省空间，避免内存碎片，提升内存利用率，线性顺序存储，对CPU高速缓存支持友好。对于查找的时间复杂度的优势提升不大。但是，由于压缩列表比较紧凑，在新增更新删除操作时可能会引发连锁更新，此时最坏为O(n^2)，但触发概率相对较低，利大于弊。

### 跳表

本质是为链表增加索引，建立多层索引，查找时从顶层的索引开始逐步往下层找，最终定位到元素，适用于范围查询的场景。查找的时间复杂度为O(logN)

### 时间复杂度

对各种数据类型操作的时间复杂度取决于底层的数据结构，对于Set，虽然名字看起来是集合，但由于底层是哈希表 + 数组，因此在SREM、SADD、SRANDMENBER命令时，时间复杂度都是O(1)

* 数据类型的范围查询，都需要进行遍历操作，一般都是比较耗时的。比如List的LRANGE、ZSet的ZRANGE、Set的SMEMBERS等

* 数据类型的统计查询，比如查看某数据类型的元素个数，时间复杂度是O(1)，因为数据结构本身就有记录了。

# 与Memcached的区别

* Redis支持存储多种数据类型：string、list、hash、set、zset；而Memcached只支持string

* Redis支持持久化：RDB快照和AOF日志；Memcached不支持持久化

* Redis支持事务，使用MULTI 和 EXEC命令，支持流水线式发送命令 ；Memcahced不支持事务，命令只能一条一条的发，当然这里的事务并不满足传统意义上的ACID

* Redis-Cluster 支持分布式存储，可以多台Redis服务器存储同样的数据；Memcached是以**一致性哈希算法**实现分布式存储，即多台Memcached服务器，Memcached根据查找的key计算出该数据在哪台服务器上

* 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘； 

  Memcached 的数据则会一直在内存中，Memcached使用固定空间分配，将内存分为一组大小不同的slab_class，每个slab_class又分为一组大小相同的slab，每个slab又包含一组大小相同的chunk，根据数据大小，放到不同的chunk里，这种管理方式避免内存碎片管理问题，但是会带来内存浪费，即每个chunk内会放小于这个chunk大小的数据，chunk里有些空间没利用到

  一致性哈希算法：构造一个长度为2的32次方的整数环，根据结点名称的Hash值([0，2^32-1])，将结点放置在这个Hash环上，根据数据的key值计算Hash值，在Hash环上顺时针查找距离这个Key的Hash值最近的结点，完成key到结点的Hash映射查找，这样当扩容结点时，只会影响到其中一个结点；为了解决负载不均衡问题，可以在此基础上增加一个虚拟层，key先在环上找到虚拟结点，再找到物理结点，将数据分散到各个结点，一般一个物理结点对应150个虚拟结点

# Redis的单线程

Redis的单线程，指的是网络IO和键值对读写由一个线程来完成，其他的如持久化、异步删除、集群数据同步都有额外的线程完成。

Redis单线程之所以能处理得很快，得益于高效的数据结构，且也采用了**多路复用机制**，在网络IO操作中能并发处理大量客户端请求。监听 + 事件驱动 + 回调 的方式，处理易阻塞的accept和recv事件。

[一文揭秘单线程的Redis为什么这么快?](https://zhuanlan.zhihu.com/p/57089960?utm_source=wechat_session&utm_medium=social&utm_oi=632939468966072320)

总结一下就是：高效的数据结构和数据压缩、纯内存操作、非阻塞IO多路复用，避免频繁的上下文切换。

**性能的影响：**

* 对big key的操作，big key在分配内存和释放内存会比较耗时
* 一些命令对应的操作时间复杂度高
* 大量Key集中过期，Redis过期机制也在主线程中执行，大量Key集中过期会导致耗时过长
* 全量返回
* 淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰Key，也会产生耗时
* 主从全量同步生产RDB快照，虽然采用fork子进程生成数据快照，但fork瞬间也会阻塞线程
* 并发量非常大的时候，尽管IO多路复用提供了很好性能，但仍有其瓶颈，无法利用CPU多核的优势

# 过期时间和数据淘汰策略

## key过期删除原理

* 定期删除策略：Redis起定时器扫描key，判断key是否过期，过期则删除。虽然可以保证过期的key会被删除，但是每次都要扫面全表会非常消耗CPU资源，且定时器有间距，有可能出现key过期，但是此时定时器还没起，key仍保存在内存中
* 惰性删除策略：每次获取key的时候才判断key是否过期，过期则删除，但如果key一直未被使用，则会一直留在内存里，浪费空间
* 所以Redis会将这两种策略整合在一起，定期删除策略不在是每次都扫描全部key，而是随机抽取一部分key进行检查，在配合惰性删除策略，正好可以弥补惰性删除策略的缺点

## 淘汰策略

当内存使用量超出时，才会执行淘汰策略，默认的淘汰策略是当内存满了只会，新写入操作会报错。

其他淘汰策略

* 在所有key中，随机移除某个key
* 在所有有设置过期时间的key中，随机移除某个key
* 在所有key中，移除最近最少使用的key
* 在所有有设置过期时间的key中，移除最近最少使用的key
* 在所有有设置过期时间的key中，有更早过期时间的key优先移除

* 在所有key中，移除访问次数最少的某个key
* 在所有有设置过期时间的key中，移除访问次数最少的某个key

# 存储与持久化

## RDB快照（Redis DataBase）

RDB快照由于保存的是数据，恢复起来会比AOF快（AOF保存的是命令），而且AOF是文本文件，RDB是二进制文件，所以RDB快照在网络传输、IO效率都比AOF好。

### 原理

将Redis中的数据全量保存的文件中，一般会使用子进程进行刷盘操作，不阻塞主线程，此时主线程仍然能处理命令。（**先全量**）

此外，会使用**Copy on Write机制（写时复制）**，解决创建快照的过程中，原有数据被修改对RDB快照的影响。当主线程对原有数据进行修改前，这块数据会被复制一份（复制引用，由bgsave子进程操作），形成副本（此时会消耗两倍内存），由子进程将该副本写入RDB文件中，由于写的是引用，主线程修改后会同步到RDB中。（**后增量**）

### 相关命令

bgsave，会调子进程创建快照写入磁盘，主线程继续处理其他命令请求

save，主线程创建快照写入磁盘，会阻塞其他命令请求

redis.conf配置里，save [时间] [次数] 表示在[时间]内有[次数]写入，就会触发bgsave命令

另外，在进行主从复制，主redis发生sync命令给从redis时，如果刚刚没有执行完bgsave，也会进行一次bgsave操作。

### 潜在风险

* 风险在于快照的创建频率，如果频繁创建快照，多快照写盘会影响磁盘IO，因此每次都进行全量快照并不可取。
* **如果频率过低，则会导致宕机时丢失的数据过多。解决方式是RDB + AOF一起使用，在两次快照期间用AOF代替。**
* 当使用copy on write机制时，主线程会为其申请额外的空间，当进行频繁的写操作时，会导致内存很快被耗光。当实例系统开启了Swap机制时，超过内存使用量部分会转移到磁盘，访问磁盘的那部分就会很慢，如果没有开启Swap机制，则会触发OOM，Redis进程可能被kill或宕机
* 另外，当出现频繁的写操作时，由于生成RDB的子进程需要CPU核运行，主线程、多个线程或后台进程会竞争使用CPU，导致性能降低。

## AOF（Append Only File）

AOF配置项：always、everysec(默认)、no(每次命令只写内存，刷盘记日志的操作由操作系统决定)

写命令记录到文件中，**默认是每秒同步一次**，所以如果发生故障，最多会丢失一秒的数据，但使用AOF保存的数据文件比RDB快照要大。

此外AOF还能选择每接收一个写命令就追加写入到AOF文件中，虽然能避免不丢数据，但每个写命令后面都跟着一个刷盘操作，对机器的负担较大，影响服务性能。

### 原理

不同与MySQL的WAL机制，AOF是先执行命令将数据写入内存，再写入日志。因为AOF会记录Redis收到的每一条命令，并以文本的形式保存，如果先写日志，并不知道命令是否是正确的，因此先写内存，让系统执行成功后，才会记录到日志中，避免错误命令。

### 潜在风险

* 执行完命令，还没来得及记录日志就宕机，此时会丢失该命令的记录和相应数据。如果使用Redis当缓存，且要保证Redis宕机时不直接读库，利用Redis的AOF机制时就要注意了。
* AOF是在命令执行后才记录日志，所以不会阻塞当前的写操作，但由于日志的写操作也是在主线程中的，虽然避免阻塞当前操作，但可能会阻塞下一个命令操作，比如刷盘时磁盘IO过慢。

### 重写机制

一般用于**避免AOF日志文件过大**，毕竟如果文件太大会影响磁盘IO、重放会太耗时。

#### 原理

AOF重写机制在重写时，Redis根据Redis现状创建一个新的AOF文件，读取Redis中所有键值对后进行写入，但在重写时不是原样copy，而是会对命令进行合并，以此减小文件大小。

重写时，主线程会fork后台的bgrewriteiaof子进程，把**主线程的内存拷贝一份给bgrewriteiaof子进程**，其中也包括了Redis的最新数据，bgrewriteiaof子进程逐一写入重写日志，避免阻塞主线程。

因为重写是在子进程中处理的，此时主线程仍然能处理客户端的命令，当接收到客户端的写命令时，**会记录到AOF日志**中，**同时**也会写进**AOF重写日志**的缓冲区，等子进程将拷贝数据写完后，再把缓冲区的数据刷入，完成后即可删除AOF文件，留下AOF重写文件。

#### 潜在风险

* 主线程fork创建bgrewriteaof子进程时，内核会把主线程的PCB内容拷贝给子进程，此时会阻塞主线程，当要拷贝的内容特别大时，fork执行的时间就会变长，阻塞主线程的时间也会变长。
* bgrewriteaof子进程会和主线程共享内存，当主线程收到新增或修改操作时，主线程会申请新的内存空间用来保存，但是如果是bigkey，主线程就会面临申请空间过大导致耗时。

# 高可用集群

RDB和AOF保证了数据少丢失，集群部署保证服务少中断，实现高可用。

## 主从复制 - 保证数据一致性

一般采用主从读写分离，主服务器进行写操作，然后再同步给从服务；而读操作发生在主从服务器均可。

如果写操作可以发生在主从服务器上，会导致主从服务器上的数据不一致，取数据时可能会取到旧值，而如果要保持一致，则需要加锁，加锁的话效率旧太差了。

一般用在**从节点**初始化加入时使用，先进行**全量同步(通过快照)**，再进行**增量同步(通过命令缓存同步)**。

### 相关命令

在从库上使用命令：Redis 5.0以前使用slaveof、之后使用replicaof  [主库IP] [主库端口]

### 过程

1. 主服务器创建RDB快照文件，发送给从服务器，并在发送期间使用缓冲区(replication buffer)记录之后收到的写命令。

   快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；整个过程中主服务器不会被阻塞。

2. 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；

3. 主服务器每执行一次写命令，就向从服务器发送相同的写命令

一般只设置一个主节点，当负载上升时，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。

解决办法：通过主从级联模式解决，可以设置主节点为根节点，向下延申，从节点再设置从节点的方式，形成树状的主从链，让从节点帮忙同步给其子节点的方式，降低主节点的压力。

同样使用命令slaveof或replicaof，只是ip换成从库的ip，这样就形成了主-从-从的模式了

## 主从库命令传播时网络中断

Redis2.8之前，如果主从库发生网络中断，重写连接时会进行全量复制，开销巨大。

2.8之后，会使用增量复制。断连期间，主库会把收到的写命令写入缓冲区(replication buffer和repl_backlog_buffer)。repl_backlog_buffer是一个环形缓冲区，主库会记录自己写到的偏移量(master_repl_offset)，从库会记录自己读到的偏移量(slave_repl_offset)。

断连时，会记录从库的偏移量，待重新连接后即可根据偏移量进行同步。由于repl_backlog_buffer是环形缓冲区，如果从库同步太慢，因此可能会出现新命令覆盖到未读取的命令，只能通过调整其大小解决，配置repl_backlog_size，否则，从库将进行全量复制。

主从模式下，从库宕机影响不大，但主库宕机就会影响从库的同步了，此时需要哨兵机制重新选举主库，保证高可用。

**replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，非共享，每个从库对应一个**

**repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer，从库共享，只是每个从库都会有复制进度标志(slave_repl_offset)记录在上面**

## 哨兵机制

哨兵机制会解决三个问题：1.判断主库是否宕机 2.选择哪个从库为主库 3.如何把新主库的信息通知给从库和客户端。

使用**哨兵模式**（sentinel）来监听和管理Redis集群，存储集群配置，作用类似ZooKeeper，哨兵节点是一台特殊的Redis，功能有限，主要用来支持哨兵机制，哨兵节点有三个任务：监控、选主、通知。

### 原理

**哨兵节点一般设置3个及以上的奇数个，哨兵节点间是平级的，会互相监控**。

* 所有哨兵节点都会周期性的给所有主从库发送Ping命令检测Redis的主从节点是否正常运行，当有Redis节点出现问题时，进行通知。
* 如果发生问题的节点是主节点，会从从节点中选出主节点，代替失效的主节点。
* 之后会把新主库的连接信息发给其他从库，让他们执行replicaof命令，和主库建立连接，并进行数据复制。同时把新主库的连接信息通知给客户端，让客户端把请求发送到新主库上。

### 如何监控，如何判断主库不可用

**主观下线**：每个哨兵节点每隔1s对主从节点发生心跳，当有节点再超过x秒后没有进行回复，此时该节点为主观下线，还需要进一步判断。

**客观下线**：当主观下线的节点是主节点时，该哨兵节点会通过`sentinel is-master-down-by-addr`命令，向其它n-1个哨兵节点询问对主节点的判断，当超过 n / 2 + 1 个哨兵节点认为主节点有问题时，该节点为客观下线。**多这一步是为了防止误判。**

客观下线后，会从从节点中选举出主节点，前主节点重新上线后会被设置为从节点

Redis没有使用什么一致性算法，仅依据**Gossip协议**在有效时间范围内收到其它Sentinel节点的确认。

另外，如果不使用哨兵模式，只使用Redis集群，也可以实现高可用，只不过是把监控和选择转移到各个节点中。

### 如何选举

哨兵节点会周期性的发送心跳给主从库，在此过程中会对各个节点进行打分。之后按照一定的筛选条件和规则，选出得分最高的从库为新主库。

* 筛选条件：从库的在线状态，之前的网络连接状态。通过设置主从库断连的最大连接超时时间（down-after-milliseconds）、断连次数（n），当超过阈值时则说明从库的网络状况不好。
* 打分规则：从库的优先级（比如不同从库的配置不一样，优先级也就不一样）、从库的复制进度（根据从库在repl_backlog_buffer中的偏移量，从库间比较）、从库的ID号（ID号小的分高）

### 如何通知

客户端在访问主从库时，不能写死主库地址，而是从哨兵节点中获取主库地址；当哨兵选出新的主库时，会更新自己存的新主库地址。哨兵节点通过 发布/订阅 机制，让客户端进行订阅和修改。从而也能让客户端了解整个主从切换过程。

### 哨兵集群的高可用

由于哨兵需要进行客观下线的判断，因此需要多个哨兵组成集群，集群就会涉及到高可用。

#### 哨兵节点间、与主从库间的相互发现机制

**哨兵节点间的相互发现**：正常情况下，每个哨兵都是平级的。每个哨兵节点在设置时的命令是`sentinel monitor <master-name> <ip> <redis-port> <quorum> `，并不感知其他哨兵的存在。**哨兵节点间的相互发现，以来Redis的 发布/订阅 机制**。哨兵节点一旦和主库建立连接，就会把自己的连接信息(如IP、端口)发布到主库上，同时它也会订阅，从而发现其他哨兵节点。

**哨兵节点发现从库：**哨兵节点连接主库后，发送INFO命令，主库就会把从库连接信息列表发给哨兵节点，从而实现哨兵节点对从库的监控。

#### 哨兵节点Leader选举原理

正常情况下哨兵集群内的每个哨兵节点是平级的，但是当触发客观下线时，需要选出一个哨兵节点Leader来执行主从库切换。重新选举主库只能由一个哨兵节点来做，如果不是，可能会出现主从库集群脑裂。另外，哨兵节点越多，选举速度越慢，风险也会增加。

哨兵节点Leader选举分为两个阶段

1. 各个哨兵节点判断主/客观下线阶段：各个哨兵在判断主库是主观下线后，首先会给自己投Yes票，之后会发送`is-master-down-by-addr`命令给其他哨兵节点，其他哨兵节点会根据自己的判断情况，回复Yes / No回去。该哨兵节点收集得到的Yes票，当超过设置的quorum值时，标记主库为客观下线。

2. 每个哨兵在一次选举节点只有一次投票机会，当有哨兵节点得出客观下线结论后，该哨兵再发起投票，进行Leader选举，当收集到的票数超过一半，则该哨兵节点成为Leader节点，如果没有选举成功，则等待一般是故障转移超时时间failover_timeout的2倍时间后会从新举行选举。

![Redis哨兵下线主库和Leader选举](https://github.com/Nixum/Java-Note/raw/master/Note/picture/Redis哨兵下线主库和Leader选举.png)

# 高可扩展集群 

一般一个Redis保存几个G内比较合适，**当单个Redis实例要保存的键值对太多时，会影响Redis的主从复制、RDB快照和AOF日志的大小、影响从库重放速度、fork子进程的速度(太慢会导致阻塞主线程)**，因此需要进行对单Redis实例扩展，常见的方式是对单个Redis实例进行扩展，一般分为纵向扩展和横向扩展。

## 扩展

* 纵向扩展：升级单Redis实例的配置，如内存容量、磁盘容量、CPU等，但会影响RDB快照和AOF日志大小，网络传输等，一般用在不使用Redis持久化功能的场景。
* 横向扩展：根据key，对Redis实例进行分片，增加Redis实例个数。

## 分片

### 原理

* 将数据分散到集群的多个机器上，Redis里使用的概念是槽Slot，每个集群的槽数固定为16 * 1024 = 16384个，使用哈希分片算法对Key进行取模，计算方法：`HASH_SLOT = CRC16(Key) mod 16384`，余数为Key所在的槽。

  之所以会使用槽，是因为要把数据和节点解耦，如果不使用槽，而是使用key与节点的映射表，当key的数量非常庞大时，映射表也会非常大，映射表的修改和迁移的性能不高。

* 集群内每台机器会存放一些槽，在集群初始化的时候会对集群内的机器**平均分配这16384个槽**，使用查表法进行分配。因此，当需要扩容时，会重新计算槽的位置和迁移key，可以使用官方提供的redis-trib.rb脚本实现。

* 客户端连接分片集群后，即可获得槽与各个Redis分片节点的映射。访问时可以访问集群内的任意节点，先根据key算出在哪个槽，在查询槽和节点间的关系，找到对应的节点进行查询。

  另外，要注意分片后，对于Keys、scan这样的扫描命令的性能就会更加差了。

* 当分片集群有增删时，槽与节点的映射也会随之修改，为了负载均衡，Redis需要把槽重新分布到各个分片上。但是客户端却不感知，当客户端发送命令时，如果节点上该槽已迁往别处，客户端会收到`MOVED 新槽编号 新槽所在的host`的错误信息，客户端将重新请求，同时修改槽与节点的映射关系。

* 如果客户端请求发生在Redis迁移槽的过程中，则会先收到`ASK 新槽编号 新槽所在的host`的错误消息，让客户端进行重试，直到Redis完成槽的迁移，重试成功。

一般的分配规模是几十个以内，不适合构建超大规模的集群，原因是去中心化设计，选举算法使用Gossip，规模越大时，插播速度越慢。如果要构建超大规模的集群，则需要增加一层代理，进行集群间的转发，例如twemproxy或者Codis这类基于代理的集群架构。

# 事务

使用 MULTI 和 EXEC 命令将多个写操作包围起来，更多的是为了减少客户端与服务端的通信次数，无法实现事务的ACID特性

# 缓存可能引发的问题以及应对方法

## 缓存雪崩

现象：缓存大面积失效导致请求到达数据库

应对方法：

1. 缓存过期时间设置均匀，不能让一大片缓存在某一时间全部失效，比如设置过期时间时加入随机数，让过期时间在一个范围内波动
2. 请求时加锁(比如利用redission的rlock)，后续请求只能等到前面的查完数据库，进行缓存后，才能继续，但会造成吞吐量降低，响应时间变长，或者可以使用semaphore设置一定的信号量，不至于只有一个请求去回源数据库
3. 不设置key的过期时间，另开一个定时任务定期全量更新缓存；或者定时任务定期扫描，将快要过期的key延迟过期时间；设置多级缓存
4. 灰度发布，对缓存进行预热

## 缓存穿透

现象：查询一个一定不存在的数据，导致请求一直到达数据库

应对方法：

1. 使用布隆过滤器，将可能出现查询的值哈希到一个bitMap中，进行拦截，虽然布隆过滤有一定的误报几率，但也能一定程度的减少穿透的影响，常见的方案是配合2一起降低穿透带来的影响
2. 如果查询结果为空，也加入缓存中（可以直接设置为空，或者使用特殊标识来表示），并设置过期时间
3. 通过异步更新服务 + 消息队列的方式进行全量缓存的更新。缓存的设置还是照旧，只是当有数据更新时，只是触发消息交给消息队列，再由异步更新服务消费消息，实现缓存更新。
4. 利用数据库的Bin Log，当数据库执行更新操作时，从数据库接收到Bin Log之后根据Bin Log更新Redis缓存，道理跟消息队列类似，只是不用担心消息发生失败问题。

## 缓存无底洞

现象：增加缓存节点，性能不升反降，原因是客户端要维护大量的连接，如果key分布在不同机器，需要查多次

应对方法：

1. 减少网络请求，能批量查尽量批量查
2. 将key进行分类，存到指定节点，查询同类的key时只需要特定的节点去查
3. 并发查询

## 主动更新缓存要注意的点

1. 不推荐先更新缓存再更新数据库，原因是数据库操作可能失败，导致缓存与数据库不一致；
2. 不推荐先更新数据库再更新缓存，原因是两者更新数据的顺序可能不一致，更新到缓存的数据也不一定被访问；
3. 不推荐先删缓存再更新数据库，访问时再进行加载，原因是并发情况下，删除缓存后来不及更新数据库，但旧值已经被其他线程读到了，或者数据库操作失败了，但缓存已经没了，其他导致还要再读一次数据库；
3. 推荐先更新数据库再删除缓存，访问时再进行加载（也称为cache aside模式），虽然也可能出现3中的情况，导致数据不一致，但带来的影响会相对小一些，如果删除缓存失败了，可以延迟任务进行删除重试，因为删除操作一般是幂等的，所以即使重复删除也没关系，另外，相比Read/Write Through模式（更新数据库后更新缓存操作），不会因为并发读写产生脏数据。还有由于会删除缓存，所以要注意缓存穿透问题。

参考：

极客时间 - Redis核心技术与实战