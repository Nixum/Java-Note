[TOC]

# 数据类型及结构

## 数据类型

String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet

## 底层数据结构

* String：简单动态字符串
* List：双向链表 + 压缩列表
* Hash：哈希表 + 压缩列表
* Set：整数数组+ 哈希表
* ZSet：跳表 + 压缩列表

### 哈希表

但无论值是什么类型的，所有的键值对会保存在**全局哈希表**中，便于快速找到对应的Key，哈希桶只会保存键值对的指针。

因此，即使Redis里存在大量数据，也不影响查找的速度，毕竟都是根据Key进行hash就能找到对应的Value，真正有影响的是哈希表的在解决哈希冲突和rehash时带来的阻塞。

**Redis的哈希表使用拉链法解决哈希冲突。通过两个全局哈希表加快rehash的操作。**

处理全局哈希表有这种操作，Hash的数据结构也是这样的操作，本质是一样的。

#### rehash过程

1. 默认使用哈希表1，此时哈希表2还没有被分配空间

2. 当数据增多至需要rehash时，为哈希表2分配空间，大小会比哈希表1大，比如大两倍

3. 把哈希表1中的数据重新映射并拷贝到哈希表2中

   **渐进式rehash**：解决大量数据在哈希表1和2之间拷贝，会导致Redis线程阻塞（因为单线程)。

   3.1 拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺便将该索引位置上的所有entries拷贝到哈希表2中；

   3.2 等待处理下一个请求时，再顺带拷贝哈希表1中该索引下一个索引位置的entries到哈希表2中；

   通过这两种方式，将一次性的大量拷贝分散到每次请求和等待间隙中。

   3.3 此外Redis本身也有一个定时任务在执行rehash，发生在空闲时间

4. 释放哈希表1的空间，此时哈希表1的空间被回收，原来的哈希表2变成哈希表1，哈希表1变成哈希表2

列表

### 压缩列表

本质上是一个数组，数组中每一个元素保存一个数据。但压缩列表在表头有三个字段：列表长度(zlbytes)、列表尾的偏移量和列表中的entry个数(zltail)、压缩列表末尾标志字段(zllen)。

压缩列表的优势在于存储结构，在查找第一个和最后一个的时候有优势，可以利用这三个字段查到，是O(1)，其他则是O(n)。底层里单纯数组可能查找最后一个元素并不友好。

压缩列表或者数组主要因为其数据结构紧凑，节省空间，避免内存碎片，提升内存利用率，对CPU高速缓存支持友好。对于查找的时间复杂度的优势提升不大。

### 跳表

本质是为链表增加索引，建立多层索引，查找时从顶层的索引开始逐步往下层找，最终定位到元素，适用于范围查询的场景。查找的时间复杂度为O(logN)

### 时间复杂度

对各种数据类型操作的时间复杂度取决于底层的数据结构，对于Set，虽然名字看起来是集合，但由于底层是哈希表 + 数组，因此在SREM、SADD、SRANDMENBER命令时，时间复杂度都是O(1)

* 数据类型的范围查询，都需要进行遍历操作，一般都是比较耗时的。比如List的LRANGE、ZSet的ZRANGE、Set的SMEMBERS等

* 数据类型的统计查询，比如查看某数据类型的元素个数，时间复杂度是O(1)，因为数据结构本身就有记录了。

# 与Memcached的区别

* Redis支持存储多种数据类型：string、list、hash、set、zset；而Memcached只支持string

* Redis支持持久化：RDB快照和AOF日志；Memcached不支持持久化

* Redis支持事务，使用MULTI 和 EXEC命令，支持流水线式发送命令 ；Memcahced不支持事务，命令只能一条一条的发，当然这里的事务并不满足传统意义上的ACID

* Redis-Cluster 支持分布式存储，可以多台Redis服务器存储同样的数据；Memcached是以**一致性哈希算法**实现分布式存储，即多台Memcached服务器，Memcached根据查找的key计算出该数据在哪台服务器上

* 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘； 

  Memcached 的数据则会一直在内存中，Memcached使用固定空间分配，将内存分为一组大小不同的slab_class，每个slab_class又分为一组大小相同的slab，每个slab又包含一组大小相同的chunk，根据数据大小，放到不同的chunk里，这种管理方式避免内存碎片管理问题，但是会带来内存浪费，即每个chunk内会放小于这个chunk大小的数据，chunk里有些空间没利用到

  一致性哈希算法：构造一个长度为2的32次方的整数环，根据结点名称的Hash值([0，2^32-1])，将结点放置在这个Hash环上，根据数据的key值计算Hash值，在Hash环上顺时针查找距离这个Key的Hash值最近的结点，完成key到结点的Hash映射查找，这样当扩容结点时，只会影响到其中一个结点；为了解决负载不均衡问题，可以在此基础上增加一个虚拟层，key先在环上找到虚拟结点，再找到物理结点，将数据分散到各个结点，一般一个物理结点对应150个虚拟结点

# Redis的单线程

Redis的单线程，指的是网络IO和键值对读写由一个线程来完成，其他的如持久化、异步删除、集群数据同步都有额外的线程完成。

Redis单线程之所以能处理得很快，得益于高效的数据结构，且也采用了**多路复用机制**，在网络IO操作中能并发处理大量客户端请求。监听 + 事件驱动 + 回调 的方式，处理易阻塞的accept和recv事件。

[一文揭秘单线程的Redis为什么这么快?](https://zhuanlan.zhihu.com/p/57089960?utm_source=wechat_session&utm_medium=social&utm_oi=632939468966072320)

总结一下就是：高效的数据结构和数据压缩、纯内存操作、非阻塞IO多路复用，避免频繁的上下文切换。

**性能的影响：**

* 对big key的操作，big key在分配内存和释放内存会比较耗时
* 一些命令对应的操作时间复杂度高
* 大量Key集中过期，Redis过期机制也在主线程中执行，大量Key集中过期会导致耗时过长
* 淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰Key，也会产生耗时
* 主从全量同步生产RDB快照，虽然采用fork子线程生成数据快照，但fork瞬间也会阻塞线程
* 并发量非常大的时候，尽管IO多路复用提供了很好性能，但仍有其瓶颈，无法利用CPU多核的优势

# 过期时间和数据淘汰策略

## key过期删除原理

* 定期删除策略：Redis起定时器扫描key，判断key是否过期，过期则删除。虽然可以保证过期的key会被删除，但是每次都要扫面全表会非常消耗CPU资源，且定时器有间距，有可能出现key过期，但是此时定时器还没起，key仍保存在内存中
* 惰性删除策略：每次获取key的时候才判断key是否过期，过期则删除，但如果key一直未被使用，则会一直留在内存里，浪费空间
* 所以Redis会将这两种策略整合在一起，定期删除策略不在是每次都扫描全部key，而是随机抽取一部分key进行检查，在配合惰性删除策略，正好可以弥补惰性删除策略的缺点

## 淘汰策略

当内存使用量超出时，才会执行淘汰策略，默认的淘汰策略是当内存满了只会，新写入操作会报错。

其他淘汰策略

* 在所有key中，随机移除某个key
* 在所有有设置过期时间的key中，随机移除某个key
* 在所有key中，移除最近最少使用的key
* 在所有有设置过期时间的key中，移除最近最少使用的key
* 在所有有设置过期时间的key中，有更早过期时间的key优先移除

* 在所有key中，移除访问次数最少的某个key
* 在所有有设置过期时间的key中，移除访问次数最少的某个key

# 存储与持久化

## RDB快照（Redis DataBase）

RDB快照由于保存的是数据，恢复起来会比AOF快（AOF保存的是命令）

### 原理

将Redis中的数据全量保存的文件中，一般会使用子线程进行刷盘操作，不阻塞主线程，此时主线程仍然能处理命令。（**先全量**）

此外，会使用Copy on Write机制，解决创建快照的过程中，原有数据被修改对RDB快照的影响，当主线程对原有数据进行修改前，这块数据会被复制一份（复制引用），形成副本（此时会消耗两倍内存），由子线程将该副本写入RDB文件中，由于写的是引用，主线程修改后会同步到RDB中。（**后增量**）

### 相关命令

bgsave，会调子线程创建快照写入磁盘，主线程继续处理其他命令请求

save，主线程创建快照写入磁盘，会阻塞其他命令请求

redis.conf配置里，save [时间] [次数] 表示在[时间]内有[次数]写入，就会触发bgsave命令

另外，在进行主从复制，主redis发生sync命令给从redis时，如果刚刚没有执行完bgsave，也会进行一次bgsave操作。

### 潜在风险

风险在于快照的创建频率，如果频繁创建快照，多快照写盘会影响磁盘IO，因此每次都进行全量快照并不可取。

**如果频率过低，则会导致宕机时丢失的数据过多。解决方式是RDB + AOF一起使用，在两次快照期间用AOF代替。**

## AOF（Append Only File）

AOF配置项：always、everysec(默认)、no(每次命令只写内存，刷盘记日志的操作由操作系统决定)

写命令记录到文件中，**默认是每秒同步一次**，所以如果发生故障，最多会丢失一秒的数据，但使用AOF保存的数据文件比RDB快照要大。

此外AOF还能选择每接收一个写命令就追加写入到AOF文件中，虽然能避免不丢数据，但每个写命令后面都跟着一个刷盘操作，对机器的负担较大，影响服务性能。

### 原理

不同与MySQL的WAL机制，AOF是先执行命令将数据写入内存，再写入日志。因为AOF会记录Redis收到的每一条命令，并以文本的形式保存，如果先写日志，并不知道命令是否是正确的，因此先写内存，让系统执行成功后，才会记录到日志中，避免错误命令。

### 潜在风险

* 执行完命令，还没来得及记录日志就宕机，此时会丢失该命令的记录和相应数据。如果使用Redis当缓存，且要保证Redis宕机时不直接读库，利用Redis的AOF机制时就要注意了。
* AOF是在命令执行后才记录日志，所以不会阻塞当前的写操作，但由于日志的写操作也是在主线程中的，虽然避免阻塞当前操作，但可能会阻塞下一个命令操作，比如刷盘时磁盘IO过慢。

### 重写机制

一般用于**避免AOF日志文件过大**，毕竟如果文件太大会影响磁盘IO、重放会太耗时。

#### 原理

AOF重写机制在重写时，Redis根据Redis现状创建一个新的AOF文件，读取Redis中所有键值对后进行写入，但在重写时不是原样copy，而是会对命令进行合并，以此减小文件大小。

重写时，主线程会fork后台的bgrewriteiaof子线程，把**主线程的内存拷贝一份给bgrewriteiaof子线程**，其中也包括了Redis的最新数据，bgrewriteiaof子线程逐一写入重写日志，避免阻塞主线程。

因为重写是在子线程中处理的，此时主线程仍然能处理客户端的命令，当接收到客户端的写命令时，**会记录到AOF日志**中，**同时**也会写进**AOF重写日志**的缓冲区，等子线程将拷贝数据写完后，再把缓冲区的数据刷入，完成后即可删除AOF文件，留下AOF重写文件。

# 高可用集群

## 主从复制

一般用在从节点初始化加入时使用，先进行全量同步(通过快照)，再进行增量同步(通过命令缓存同步)

**过程：**

1. 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；
2. 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；
3. 主服务器每执行一次写命令，就向从服务器发送相同的写命令

一般只设置一个主节点，当负载上升时，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载，此时可以通过设置主节点为根节点，向下延申，从节点再设置从节点的方式，形成树状的主从链，让从节点帮忙同步给其子节点的方式，降低主节点的压力。

## 哨兵机制

一般是使用**哨兵模式**（sentinel）来监听和管理Redis集群，存储集群配置，作用类似ZooKeeper，哨兵节点本身也是一台Redis，但功能有限，主要同来支持哨兵机制。

**哨兵节点一般设置3个及以上的奇数个，哨兵节点间是平级的，会互相监控**。所有的哨兵节点都会不断检测Redis的主从节点是否正常运行，当有Redis节点出现问题时，进行通知，如果发生问题的节点是主节点，会从从节点中选出主节点，代替失效的主节点。

**主观下线**：每个哨兵节点每隔1s对主从节点发生心跳，当有节点再超过x秒后没有进行回复，此时该节点为主观下线，还需要进一步判断。

**客观下线**：当主观下线的节点是主节点时，该哨兵节点会通过sentinel is-master-down-by-addr命令，向其它哨兵节点询问对主节点的判断，当超过 y 个哨兵节点认为主节点有问题时，该节点为客观下线。

客观下线后，会从从节点中选举出主节点，前主节点重新上线后会被设置为从节点

Redis没有使用什么一致性算法，仅依据**Gossip协议**在有效时间范围内收到其它Sentinel节点的确认。

另外，如果不使用哨兵模式，只使用Redis集群，也可以实现高可用，只不过是把监控和选择转移到各个节点中。

# 高可扩展集群 

## 分片

将数据分散到集群的多个机器上，Redis里使用的概念是槽Slot，每个集群的槽数固定为16 * 1024 = 16384个，使用哈希分片算法对Key进行取模，计算方法：`HASH_SLOT = CRC16(Key) mod 16384`，余数为Key所在的槽。集群内每台机器会存放一些槽，在集群初始化的时候会对集群内的机器平均分配这16384个槽，使用查表法进行分配。因此，当需要扩容时，会重新计算槽的位置和迁移key，可以使用官方提供的redis-trib.rb脚本实现。

访问时可以访问集群内的任意节点，先根据key算出在哪个槽，在查询槽和节点间的关系，找到对应的节点进行查询。另外，要注意分片后，对于Keys、scan这样的扫描命令的性能就会更加差了。

一般的分配规模是几十个以内，不适合构建超大规模的集群，原因是去中心化设计，选举算法使用Gossip，规模越大时，插播速度越慢。如果要构建超大规模的集群，则需要增加一层代理，进行集群间的转发，例如twemproxy或者Codis这类基于代理的集群架构

# 事务

使用 MULTI 和 EXEC 命令将多个写操作包围起来，更多的是为了减少客户端与服务端的通信次数，无法实现事务的ACID特性

# 缓存可能引发的问题以及应对方法

## 缓存雪崩

现象：缓存大面积失效导致请求到达数据库

应对方法：

1. 缓存过期时间设置均匀，不能让一大片缓存在某一时间全部失效，比如设置过期时间时加入随机数，让过期时间在一个范围内波动
2. 请求时加锁(比如利用redission的rlock)，后续请求只能等到前面的查完数据库，进行缓存后，才能继续，但会造成吞吐量降低，响应时间变长，或者可以使用semaphore设置一定的信号量，不至于只有一个请求去回源数据库
3. 不设置key的过期时间，另开一个定时任务定期全量更新缓存；或者定时任务定期扫描，将快要过期的key延迟过期时间；设置多级缓存
4. 灰度发布，对缓存进行预热

## 缓存穿透

现象：查询一个一定不存在的数据，导致请求一直到达数据库

应对方法：

1. 使用布隆过滤器，将可能出现查询的值哈希到一个bitMap中，进行拦截，虽然布隆过滤有一定的误报几率，但也能一定程度的减少穿透的影响，常见的方案是配合2一起降低穿透带来的影响
2. 如果查询结果为空，也加入缓存中（可以直接设置为空，或者使用特殊标识来表示），并设置过期时间
3. 通过异步更新服务 + 消息队列的方式进行全量缓存的更新。缓存的设置还是照旧，只是当有数据更新时，只是触发消息交给消息队列，再由异步更新服务消费消息，实现缓存更新。
4. 利用数据库的Bin Log，当数据库执行更新操作时，从数据库接收到Bin Log之后根据Bin Log更新Redis缓存，道理跟消息队列类似，只是不用担心消息发生失败问题。

## 缓存无底洞

现象：增加缓存节点，性能不升反降，原因是客户端要维护大量的连接，如果key分布在不同机器，需要查多次

应对方法：

1. 减少网络请求，能批量查尽量批量查
2. 将key进行分类，存到指定节点，查询同类的key时只需要特定的节点去查
3. 并发查询

## 主动更新缓存要注意的点

1. 不推荐先更新缓存再更新数据库，原因是数据库操作可能失败，导致缓存与数据库不一致；
2. 不推荐先更新数据库再更新缓存，原因是两者更新数据的顺序可能不一致，更新到缓存的数据也不一定被访问；
3. 不推荐先删缓存再更新数据库，访问时再进行加载，原因是并发情况下，删除缓存后来不及更新数据库，但旧值已经被其他线程读到了，或者数据库操作失败了，但缓存已经没了，其他导致还要再读一次数据库；
3. 推荐先更新数据库再删除缓存，访问时再进行加载（也称为cache aside模式），虽然也可能出现3中的情况，导致数据不一致，但带来的影响会相对小一些，如果删除缓存失败了，可以延迟任务进行删除重试，因为删除操作一般是幂等的，所以即使重复删除也没关系，另外，相比Read/Write Through模式（更新数据库后更新缓存操作），不会因为并发读写产生脏数据。还有由于会删除缓存，所以要注意缓存穿透问题。

参考：

极客时间 - Redis核心技术与实战