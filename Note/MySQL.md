[TOC]

# 常用SQL

## Count(\*)、Count(1)、Count([列])区别
    1. Count(\*)或者Count(1) 返回的数量都一样，count(\*)会引起全表扫描
    2. Count（列）会计算列或这列的组合不为空的计数。
    3. 假如表沒有主键(Primary key), 那么count(1)比count(\*)快，
    4. 如果有主键的話，那主键作为count的条件时候count(主键)最快
    5. 如果你的表只有一个字段的话那count(\*)就是最快的
    6. count(\*) 跟 count(1) 的结果一样，都包括对NULL的统计，而count(column) 是不包括NULL的统计

## having的使用

* having一般需要搭配 group by 使用，在group by之后，order by之前

* having一般配合聚合函数使用，而where后面不能加聚合函数

* where是对**表的字段**进行条件过滤，having是对**select出来的字段**进行条件过滤

  可以想成 查询一些字段，先通过where进行一次过滤，group by进行一次分组，having对分组后的结果再过滤一次，having后的字段必须出现在select中

常见一点的sql，比如有如下表，这里为了方便理解以中文的形式表示字段

```sql
+-----+--------Log------+------------+
|  id | 网站名称 | 点击数 | date        |
+-----+---------+-------+------------+
|   1 |       A |    10 | 2016-05-10 |
|   2 |       C |    60 | 2016-05-13 |
|   3 |       A |   230 | 2016-05-14 |
|   4 |       B |    45 | 2016-05-14 |
|   5 |       E |   545 | 2016-05-14 |
|   6 |       D |    13 | 2016-05-15 |
|   7 |       C |   105 | 2016-05-15 |
|   8 |       E |   660 | 2016-05-16 |
|   9 |       C |   301 | 2016-05-17 |
+-----+---------+-------+------------+
```

查询 除了D网站外 各个网站的点击数 大于100 的 网站名称 和 点击数 并 降序 表示

select 网站名称, **SUM(点击数)**   
from Log where 网站名称!='D'   
group by 网站名称 **having** **SUM(点击数)**>100 order by SUM(点击数)  

## 日期类查询

- curdate()函数：得到今天的日期，格式： 年-月-日

- now()函数：得到今天的日期和时间，格式：年-月-日 时:分:秒

- 两个datetime类型的字段相减，得到的单位跟日期的格式有关，如果格式有到秒，那减出来就是多少秒，如果格式只到日，那减出来就是多少日

- UNIX_TIMESTAMP(datetime类型的字段) 将datetime类型的字段转换为时间戳，要注意时间戳是以1970 年 1 月 1 日开始算的

- DATE_SUB(date, INTERVAL expr type) 函数：从日期减去指定的时间间隔

  date_format(date字段, ‘%Y%m%d %H:%i:%s') 函数：日期格式化函数，

  可以利用这些来查询最近多少天的数据如

  查询 近一小时的数据 where date字段 >= DATE_SUB(now(), INTERVAL 1 Hour) and date字段 < now()

  查询 昨天的数据 where date字段 >= DATE_SUB(CURDATE(), INTERVAL 1 Day) and date字段 < CURDATE()

  查询 近7天的数据 where date字段 >= DATE_SUB(CURDATE(), INTERVAL 7 Day) 

  查询 本月的数据 where date_format(date字段, ‘%Y%m') = date_format(curdate() , ‘%Y%m')

  查询 上个月的数据 where period_diff(date_format(now() , ‘%Y%m') , date_format(date字段, ‘%Y%m')) =1

  查询 今年的数据 where YEAR(date字段)=YEAR(NOW())

  查询 去年的数据  where YEAR(date字段)=year(date_sub(now(),interval 1 year))

  查询本季和上一季的跟 查年的差不多 ，把 YEAR函数 换成 QUARTER函数 即可

# 数据类型

## Datetime

* 保存从 1001 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间
* 与时区无关

## TimeStamp

* 和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年

* 它和时区有关，每个时间戳在不同时区所代表的具体时间不同

* 默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间

* MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，

  提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳

# 索引

## 1.常见索引及概念

* 聚集索引：每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据。一个表只能包含一个聚集索引，聚集索引通常提供更快的数据访问速度。
* 非聚集索引：表中行的物理顺序与键值的逻辑顺序不匹配，查到记录对应的主键值 ，再使用主键的值通过聚集索引查找到需要的数据，要细分的话可以分为普通索引，唯一索引，组合索引，全文索引这些。
* 稠密索引：每个索引对应一个值
* 稀疏索引：每个索引对应一个存储块
* 覆盖索引：要查询的字段只需要去查询索引表就可以

## 2.特点

需要建立的列：经常需要搜索的列、主键列、外键列、排序的列、经常在where后面出现的列

* 避免进行数据库全表的扫描，大多数情况，只需要扫描较少的索引页和数据页，而不是查询所有数据页。而且对于非聚集索引，有时不需要访问数据页即可得到数据。
* 聚集索引可以避免数据插入操作，集中于表的最后一个数据页面。
* 在某些情况下，索引可以避免排序操作
* 加速表与表之间的连接
* 在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间
* 增，删，改会带来不小性能开销

## 3.原理

[什么是B+树、B-树](https://www.sohu.com/a/156886901_479559 "")

b+树：表的数据为叶子节点，非叶子节点为索引，有两条路径，一条是树，一条是各叶子相连	（mysql）

注意

![B+树](https://github.com/Nixum/Java-Note/blob/master/Note/picture/B+树.png)

b-树，也称b树：所有节点为表的数据，只有一条路，从根节点开始

![B树](https://github.com/Nixum/Java-Note/blob/master/Note/picture/B树.png)                                                                                

### 为什么说B+树比B树更适合数据库索引

> B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。
>
> B+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
>
> 由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。

### 与红黑树的比较

- 红黑树出度为2，B+树出度不止2，因此红黑树的高度会比B+树高，查找的次数也多了

- B+树在降低磁盘I/O操作数方面占优势

  > 为了减少磁盘 I/O，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，速度会非常快。
  >
  > 操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。

## 4.失效情况

在使用到索引列的情况下

* 对索引列作运算如 + - * / !
* 索引属性出错，比如该索引列是字符串，但是写时候没有加``号
* 模糊查询 like ‘%keyword%` 查询不能有前置的%，如果是 like ‘keyword%’ 这样还是可以用到索引的
* 索引列里有字段为null，null值不会加入到索引中
* 使用or连接条件，如果or连接的条件中有一个不是索引，会失效，可以改成使用union all来连接两条sql语句
* 组合索引没有体现最左匹配
* is null / is not null 对索引作判断
* 索引上使用  != 或者 <> 还有not in
* 索引的值只有几种情况，如性别只有男和女，这种情况虽然也会用索引，只是意义不大
* 表的量级较小，存储引擎判定使用全表扫描更快

## 5.优化

* 注意区分度，使用这个计算 count(distinct  left(列名,  索引长度)) / count(*) from table，区分度越高越好
* 其他参考

## 6.分析

### 使用explain

Explain + SQL语句，给出该SQL语句的分析结果，看看查询的类型，有没有用到索引，是不是全表扫描

比较重要的字段：

* **select_type**：查询类型，如 简单查询、联合查询、子查询等

* **type**：访问类型，ALL(全表扫描)、index(索引查询)、range(索引范围查询)、ref(表间的连接匹配条件)、const(常量)，一个好的SQL起码得达到range级

* **Key**：索引列的名称

* **rows**：扫描的行数

### 慢查询分析



# 存储引擎

## 1.MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

不支持事务。

不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

## 2.InnoDB

是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。

实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

## 3.区别

* MyISAM是非事务安全；InnoDB是事务安全型
* MyISAM的锁是表锁；InnoDB支持行锁
* MyISAM支持全文索引；InnoDB不支持（5.6版本后才支持）
* MyISAM适合 `SELECT` 密集型的表；InnoDB适合 `INSERT` 和 `UPDATE` 密集型的表
* MyISAM表是保存成文件形式，跨平台转移方便
* InnoDB表比MyISAM表安全
* MyISAM对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用
* MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢；InnoDB支持安全恢复
* MyISAM不支持外键；InnoDB 支持外键，InnoDB 支持在线热备份

# 事务

## 1.ACID原则

原子性（atomicity）、一致性（consistency）、隔离性（isolation）和持久性（durability）

* 原子性：事务中的所有操作要么全部提交成功，要么全部失败回滚
* 一致性：数据库总是从一个一致性的状态转换到另一个一致性的状态
* 隔离性：一个事务所做的修改在最终提交以前，对其他事务是不可见的
* 持久性：一旦事务提交，则其所做的修改将永久保存到数据库

## 2.并发情况下带来的问题

* 脏读：如有事务A和B，A读取了B未提交的数据
* 不可重复读：如有事务A和B，A负责读取，B负责写入，A连续读的过程中B写入了一次，A前后两次读出来的数据不一样
* 丢失更新：如有事务A和B，AB均写入数据，A写入的数据被B覆盖
* 幻读：如有事务A和B，A修改表内数据的过程中，B向表内插入了一条数据，A修改完后发现数据并没有被全部修改完

## 3.事务隔离级别

* DEFAULT：默认隔离级别，即使用底层数据库默认的隔离级别；

* READ_UNCOMMITTED：未提交读，保证了读取过程中不会读取到非法数据。隔离级别在于处理多事务的并发问题，可能出现 脏读、不可重复读、丢失更新、幻读；

* READ_COMMITTED：提交读，大多数主流数据库的默认事务等级，保证了一个事务不会 读 到另一个并行事务已修改但未提交的数据，避免了“脏读”。该级别适用于大多数系统，可能出现不可重复读、丢失更新；

* REPEATABLE_READ：可重复读，保证了一个事务不会 修改 已经由另一个事务读取但未提交（回滚）的数据。避免了"脏读"和"不可重复读取"，"丢失更新"的情况，可能存在幻读；mysql默认是此隔离级别

  MySQL使用MVCC和间隙锁来防止 幻读

* SERIALIZABLE：序列化,最严格的级别，事务串行执行,即一个事务要等待另一个事务完成才可进行

## 4.传播行为（Spring）

* PROPERGATION_MANDATORY：方法必须运行在事务中，如果当前事务不存在，抛异常
* PROPAGATION_NESTED：当前事务存在，则该方法运行在嵌套事务中
* PROPAGATION_NEVER：方法不能运行事务中，否则抛异常
* PROPAGATION_REQUIRED：当前方法必须运行在事务中，如果当前存在事务，该方法运行其中，否则创建新事务
* PROPAGATION_REQUIRES_NEW：当前方法必须运行在事务中，如果当前存在事务，则该事务在方法运行期间被挂起
* PROPAGATION_SUPPORTS：当前方法不需要运行在事务中，但如果存在事务，也可运行在事务中
* PROPAGATION_NOT_SUPPORTED：当前方法不能运行在事务中，如果存在事务，则挂起该方法

# 锁

* 多版本并发控制（MVCC）：用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。MVCC 在语境中倾向于 “对多行数据打快照造平行宇宙”，然而 CAS 一般只是保护单行数据而已

* 共享锁：事务T对数据A加上共享锁，其他事务只能对A添加共享锁，不能加排他锁，获取共享锁的事务只能读不能写
* 排他锁：事务T对数据A加上排他锁，则其他事务不能再对A加任何类型的锁。获得排它锁的事务即能读数据又能修改数据
* 间隙锁：当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做间隙锁

# CAP理论

[CAP 定理的含义](http://www.ruanyifeng.com/blog/2018/07/cap.html)，CAP是针对分布式数据库的

还有BASE，可以理解成低配版CAP，达到一个基本的标准

# 大表优化

[MySQL大表优化方案](https://segmentfault.com/a/1190000006158186)

# 分库分表

## 分表

* 分为水平拆分(对行)和垂直拆分(对列)

水平拆分，针对某一列做哈希取模，平均分配到各个分表中，如果要扩容，由于模会变，导致数据要重新哈希，停机迁移数据，这样是不行的，因此一开始要设计好，例如使用一致性哈希算法，减少迁移的数据量；或者分表的时候取2的n次方，这样扩容的时候也以2的n次进行扩容，这样原来的key重新取模是在原来的位置或者原来的2倍；或者换个数据库了，像上面大表优化里面提到的那样，其他的目前还想不出还有什么方案

# 主从复制

## 原理

利用MySQL中的bin-log二进制文件，该文件记录了所有sql语句，把主数据库的bin-log文件发送给从数据库，在从数据库的relay-log重做日志文件中再执行一次这些sql语句

## 具体步骤

每个MySQL数据库上都有这三个线程

- **binlog 线程** ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。
- **I/O 线程** ：负责从主服务器上读取二进制日志，并写入从服务器的重放日志（Replay log）中。
- **SQL 线程** ：负责读取重放日志并重放其中的 SQL 语句。

![MySQL主从复制](https://github.com/Nixum/Java-Note/blob/master/Note/picture/MySQL主从复制.png)

针对复制同步带来的读延时问题，可以采取 一主多从，主写从读，分散压力；利用好缓存中间件；持久化层的处理

## 读写分离

主数据库负责写，从数据库负责读，从而缓解锁的争用、节约系统开销

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器

[MySQL主从复制](https://www.cnblogs.com/a8457013/p/7819018.html)

# JDBC

SUN的 JDBC 是一套接口，而实现是各个数据库厂商的驱动包，因此使用了桥接模式

DriverManager注册驱动包，com.mysql.jdbc.Driver类中的static块会创建驱动实例，因此只需要把驱动字节码加载到JVM里即可，Class.forName(“com.mysql.jdbc.Driver”); 

Connection conn = DriverManager.getConnection(url, username, password)获取连接

Statement stmt = con.createStatement(); 之后使用stmt的方法执行SQL语句即可，返回ResultSet

ResultSet下标从1开始

使用Connection类的setAutoCommit(false) 方法来实现事务，以这个开始，Connection类的commit()方法提交，Connection类的rollback()方法回滚

最后关闭ResultSet、Statement和Connection

# 数据库连接池

链表实现，在使用连接对象之前，先创建好一定数量的连接对象，以链表的形式连接，从端首取，用完回到段尾。

当池子中没有连接对象可取时，就让其先等待，如果等待超时还没有回获取到连接对象，就新建一个连接对象让其使用，用完后销毁该创建的对象

连接池负责管理、监控和维护这些连接对象

连接池单例

连接池需要保证线程安全

# 参考

[MySQL ACID及四种隔离级别的解释](https://www.cnblogs.com/xuanzhi201111/p/4103696.html)

[CyC2018/CS-Notes/MySQL](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/MySQL.md)